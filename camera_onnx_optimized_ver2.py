import numpy as np
import os, platform
# Wayland í™˜ê²½ì—ì„œ Qt í”Œë«í¼ í”ŒëŸ¬ê·¸ì¸ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ Linuxì—ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ XCB ì‚¬ìš©
if platform.system() == "Linux" and os.environ.get("QT_QPA_PLATFORM", "") == "":
    os.environ["QT_QPA_PLATFORM"] = "xcb"
import cv2
from PIL import ImageFont, ImageDraw, Image
import time
import os
import ollama
import onnxruntime as ort
from onnxruntime.quantization import quantize_dynamic, QuantType
import psutil
import threading
import queue

# --- ì„¤ì • ---
CAPTURE_INTERVAL = 1  # ìº¡ì²˜ ê°„ê²© (ì´ˆ)
CAPTURE_COUNT = 5     # ìº¡ì²˜ íšŸìˆ˜
CAPTURE_FOLDER = "captures" # ìº¡ì²˜ ì´ë¯¸ì§€ ì €ì¥ í´ë”
OLLAMA_MODEL = "gemma3:1b" # ì‚¬ìš©í•  Ollama ëª¨ë¸

# ì¹´ë©”ë¼ ì„¤ì • (ë¼ì¦ˆë² ë¦¬ íŒŒì´ 5 ìµœì í™”ë¥¼ ìœ„í•´ ì¡°ì • ê°€ëŠ¥)
CAMERA_WIDTH = 640
CAMERA_HEIGHT = 480
CAMERA_FPS = 15

PREDICTION_SMOOTHING_WINDOW_SIZE = 5 # ì˜ˆì¸¡ ê²°ê³¼ ìŠ¤ë¬´ë”©ì„ ìœ„í•œ í”„ë ˆì„ ìˆ˜ (5~10 ì •ë„ ê¶Œì¥)
DISPLAY_UPDATE_INTERVAL_MS = 400 # í™”ë©´ì— í‘œì‹œë˜ëŠ” ì˜ˆì¸¡ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì£¼ê¸° (ë°€ë¦¬ì´ˆ)

# ëª¨ë¸ ê²½ë¡œ ì„¤ì •

ONNX_MODEL_PATH = "./model/skin_model.onnx"
ONNX_OPTIMIZED_PATH = "./model/skin_model_quantized.onnx" # ìì˜ì ìœ¼ë¡œ ë°”ê¿”ì„œ ìµœì í™” ëª¨ë¸ ê²½ë¡œ ì„¤ì •
ONNX_QUANTIZED_PATH = "./model/skin_model_quantized_dynamic.onnx"
TFLITE_MODEL_PATH = "./model/skin_model_quantized.tflite"

# --- OSë³„ ì„¤ì • í•¨ìˆ˜ ---
def get_system_font_path():
    """OSë³„ ì‹œìŠ¤í…œ í°íŠ¸ ê²½ë¡œ ë°˜í™˜"""
    system = platform.system()
    
    if system == "Windows":
        return "C:/Windows/Fonts/malgun.ttf"
    elif system == "Linux":
        # Ubuntu/Debian ê³„ì—´
        linux_fonts = [
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
            "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",
            "/usr/share/fonts/TTF/NanumGothic.ttf",  # Arch Linux
            "/System/Library/Fonts/Helvetica.ttc"    # macOS backup
        ]
        for font in linux_fonts:
            if os.path.exists(font):
                return font
    elif system == "Darwin":  # macOS
        return "/System/Library/Fonts/AppleGothic.ttf"
    
    # ê¸°ë³¸ê°’ (í°íŠ¸ê°€ ì—†ëŠ” ê²½ìš°)
    return None

def get_backup_model_path():
    """ë°±ì—… H5 ëª¨ë¸ ê²½ë¡œ ë°˜í™˜ (OS ë¬´ê´€)"""
    possible_paths = [
        "./model/jaehong_skin_model.h5",  # ìƒëŒ€ ê²½ë¡œ (ìš°ì„ )
        "../pth/jaehong_skin_model.h5",   # ìƒìœ„ í´ë”
        "./jaehong_skin_model.h5",       # í˜„ì¬ í´ë”
        "C:/Users/kccistc/project/pth/jaehong_skin_model.h5",  # Windows ì ˆëŒ€ ê²½ë¡œ
        "/home/kccistc/project/pth/jaehong_skin_model.h5"       # Linux ì ˆëŒ€ ê²½ë¡œ
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    return None

# --- í´ë˜ìŠ¤ ë° ëª¨ë¸ ì„¤ì • ---
# í´ë˜ìŠ¤ëª… (7ê°œ í´ë˜ìŠ¤)
class_names_kr = [
    'ê¸°ì €ì„¸í¬ì•”',
    'í‘œí”¼ë‚­ì¢…',
    'í˜ˆê´€ì¢…',
    'ë¹„ë¦½ì¢…',
    'ì •ìƒí”¼ë¶€',
    'í¸í‰ì„¸í¬ì•”',
    'ì‚¬ë§ˆê·€'
]

# --- ìµœì í™”ëœ ONNX ëª¨ë¸ í´ë˜ìŠ¤ ---
class OptimizedONNXModel:
    def __init__(self, model_path, optimization_level="all", use_gpu=False):
        """
        ìµœì í™”ëœ ONNX ëª¨ë¸ ë¡œë“œ
        
        Args:
            model_path: ëª¨ë¸ ê²½ë¡œ
            optimization_level: ìµœì í™” ë ˆë²¨ ("disable", "basic", "extended", "all")
            use_gpu: GPU ì‚¬ìš© ì—¬ë¶€
        """
        self.model_path = model_path
        self.optimization_level = optimization_level
        self.use_gpu = use_gpu
        
        # ì„¸ì…˜ ì˜µì…˜ ì„¤ì •
        self.session_options = ort.SessionOptions()
        
        # ìµœì í™” ë ˆë²¨ ì„¤ì •
        if optimization_level == "disable":
            self.session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_DISABLE_ALL
        elif optimization_level == "basic":
            self.session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_BASIC
        elif optimization_level == "extended":
            self.session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_EXTENDED
        else:  # "all"
            self.session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        
        # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
        cpu_count = psutil.cpu_count(logical=False)
        self.session_options.intra_op_num_threads = cpu_count
        self.session_options.inter_op_num_threads = cpu_count
        
        # ë©”ëª¨ë¦¬ íŒ¨í„´ ìµœì í™”
        self.session_options.enable_mem_pattern = True
        self.session_options.enable_cpu_mem_arena = True
        
        # ì‹¤í–‰ ì œê³µì ì„¤ì •
        providers = self._get_providers()
        
        try:
            # ONNX ì„¸ì…˜ ìƒì„±
            self.session = ort.InferenceSession(
                model_path, 
                sess_options=self.session_options,
                providers=providers
            )
            
            # ì…ì¶œë ¥ ì •ë³´
            self.input_name = self.session.get_inputs()[0].name
            self.output_name = self.session.get_outputs()[0].name
            
            # ëª¨ë¸ ì •ë³´ ì¶œë ¥
            print(f"âœ… ìµœì í™”ëœ ONNX ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_path}")
            print(f"   ğŸ”§ ìµœì í™” ë ˆë²¨: {optimization_level}")
            print(f"   ğŸ§µ Intra-op threads: {self.session_options.intra_op_num_threads}")
            print(f"   ğŸ§µ Inter-op threads: {self.session_options.inter_op_num_threads}")
            print(f"   ğŸ’» ì‚¬ìš© ì¤‘ì¸ Providers: {self.session.get_providers()}")
            
        except Exception as e:
            print(f"âŒ ìµœì í™”ëœ ONNX ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _get_providers(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¤í–‰ ì œê³µì ë°˜í™˜"""
        providers = []
        available_providers = ort.get_available_providers()
        system = platform.system()
        
        # GPU ì‚¬ìš© ì‹œë„
        if self.use_gpu:
            # DirectML (Windowsë§Œ)
            if system == "Windows" and 'DmlExecutionProvider' in available_providers:
                providers.append('DmlExecutionProvider')
                print("ğŸ® DirectML Provider ì‚¬ìš© (Windows GPU)")
            
            # CUDA (NVIDIA - ëª¨ë“  OS)
            if 'CUDAExecutionProvider' in available_providers:
                providers.append('CUDAExecutionProvider')
                print("ğŸš€ CUDA Provider ì‚¬ìš© (NVIDIA GPU)")
            
            # ROCm (AMD - Linux)
            if system == "Linux" and 'ROCMExecutionProvider' in available_providers:
                providers.append('ROCMExecutionProvider')
                print("ğŸ”¥ ROCm Provider ì‚¬ìš© (AMD GPU)")
            
            # OpenVINO (Intel - ëª¨ë“  OS)
            if 'OpenVINOExecutionProvider' in available_providers:
                providers.append('OpenVINOExecutionProvider')
                print("âš¡ OpenVINO Provider ì‚¬ìš© (Intel GPU)")
            
            # TensorRT (NVIDIA - Linux ì£¼ë¡œ)
            if 'TensorrtExecutionProvider' in available_providers:
                providers.append('TensorrtExecutionProvider')
                print("ğŸï¸ TensorRT Provider ì‚¬ìš© (NVIDIA GPU)")
        
        # CPUëŠ” í•­ìƒ ë°±ì—…ìœ¼ë¡œ ì¶”ê°€
        providers.append('CPUExecutionProvider')
        
        return providers
    
    def predict(self, input_data):
        """ìµœì í™”ëœ ì˜ˆì¸¡"""
        try:
            result = self.session.run([self.output_name], {self.input_name: input_data})
            return result[0]
        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return None

# --- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ í•¨ìˆ˜ ---
def benchmark_model(model, test_data, num_runs=100):
    """ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹"""
    print(f"ğŸƒ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ì‹œì‘ ({num_runs}íšŒ ì‹¤í–‰)...")
    
    # ì›Œë°ì—…
    for _ in range(10):
        model.predict(test_data)
    
    # ì‹¤ì œ ë²¤ì¹˜ë§ˆí‚¹
    start_time = time.time()
    for _ in range(num_runs):
        model.predict(test_data)
    end_time = time.time()
    
    avg_time = (end_time - start_time) / num_runs * 1000  # ms
    fps = 1 / (avg_time / 1000)
    
    print(f"   âš¡ í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_time:.2f}ms")
    print(f"   ğŸ¯ ì´ˆë‹¹ í”„ë ˆì„: {fps:.1f} FPS")
    
    return avg_time, fps

# --- ë¹„ë™ê¸° ì˜ˆì¸¡ í´ë˜ìŠ¤ ---
class AsyncPredictor:
    def __init__(self, model):
        self.model = model
        self.input_queue = queue.Queue(maxsize=2)
        self.output_queue = queue.Queue(maxsize=2)
        self.prediction_thread = threading.Thread(target=self._prediction_worker)
        self.prediction_thread.daemon = True
        self.prediction_thread.start()
        self.last_prediction = None
    
    def _prediction_worker(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì˜ˆì¸¡ ì‘ì—…ì"""
        while True:
            try:
                input_data = self.input_queue.get(timeout=0.1)
                result = self.model.predict(input_data)
                
                # ê²°ê³¼ íê°€ ê°€ë“ ì°¬ ê²½ìš° ì´ì „ ê²°ê³¼ ì œê±°
                if self.output_queue.full():
                    try:
                        self.output_queue.get_nowait()
                    except queue.Empty:
                        pass
                
                self.output_queue.put(result)
                self.input_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ ë¹„ë™ê¸° ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
    
    def predict_async(self, input_data):
        """ë¹„ë™ê¸° ì˜ˆì¸¡ ìš”ì²­"""
        # ì…ë ¥ íê°€ ê°€ë“ ì°¬ ê²½ìš° ì´ì „ ìš”ì²­ ì œê±°
        if self.input_queue.full():
            try:
                self.input_queue.get_nowait()
            except queue.Empty:
                pass
        
        try:
            self.input_queue.put_nowait(input_data)
        except queue.Full:
            pass
    
    def get_prediction(self):
        """ì˜ˆì¸¡ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°"""
        try:
            result = self.output_queue.get_nowait()
            self.last_prediction = result
            return result
        except queue.Empty:
            return self.last_prediction

# --- ëª¨ë¸ ì´ˆê¸°í™” í•¨ìˆ˜ ---
def initialize_optimized_model():
    """ìµœì í™”ëœ ëª¨ë¸ ì´ˆê¸°í™”"""
    print("ğŸš€ ìµœì í™”ëœ ONNX ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘...")
    
    # 1. ì›ë³¸ ONNX ëª¨ë¸ í™•ì¸
    if not os.path.exists(ONNX_MODEL_PATH):
        print(f"âŒ ì›ë³¸ ONNX ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {ONNX_MODEL_PATH}")
        print("ğŸ’¡ ë¨¼ì € convert_h5_to_onnx.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ ë³€í™˜í•˜ì„¸ìš”.")
        return None, None
    
    # 2. ìµœì í™”ëœ ëª¨ë¸ ë¡œë“œ ì‹œë„ (ìš°ì„ ìˆœìœ„ëŒ€ë¡œ)
    models_to_try = [
        (ONNX_QUANTIZED_PATH, "ë™ì  ì–‘ìí™” ONNX"),
        (ONNX_MODEL_PATH, "ê¸°ë³¸ ONNX")
    ]
    
    for model_path, description in models_to_try:
        if os.path.exists(model_path):
            try:
                # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
                use_gpu = len([p for p in ort.get_available_providers() 
                              if p in ['CUDAExecutionProvider', 'DmlExecutionProvider', 'OpenVINOExecutionProvider']]) > 0
                
                model = OptimizedONNXModel(
                    model_path, 
                    optimization_level="all",
                    use_gpu=use_gpu
                )
                
                print(f"âœ… {description} ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
                return model, description
                
            except Exception as e:
                print(f"âŒ {description} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
    
    # 4. ë°±ì—…ìœ¼ë¡œ H5 ëª¨ë¸ ì‹œë„
    try:
        import tensorflow as tf
        from tensorflow import keras
        h5_model_path = get_backup_model_path()
        if h5_model_path and os.path.exists(h5_model_path):
            model = keras.models.load_model(h5_model_path)
            print(f"âœ… ë°±ì—… H5 ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {h5_model_path}")
            return model, "H5 ë°±ì—…"
        else:
            print("âŒ ë°±ì—… H5 ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    except Exception as e:
        print(f"âŒ ë°±ì—… H5 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    return None, None

# --- Ollama Gemma3 í•¨ìˆ˜ ---
# í´ë˜ìŠ¤ ì´ë¦„ (í•œê¸€ â†’ ì˜ì–´ ë³€í™˜ìš©, ë˜ëŠ” UI í‘œê¸°ìš©)
class_names_kr = [
    'ê¸°ì €ì„¸í¬ì•”',
    'í‘œí”¼ë‚­ì¢…',
    'í˜ˆê´€ì¢…',
    'ë¹„ë¦½ì¢…',
    'ì •ìƒí”¼ë¶€',
    'í¸í‰ì„¸í¬ì•”',
    'ì‚¬ë§ˆê·€'
]

def get_solution_from_gemma(disease_name):
    """
    ë¡œì»¬ Ollamaì˜ Gemma3 ëª¨ë¸ì—ê²Œ í”¼ë¶€ ì§ˆí™˜ì— ëŒ€í•œ ê°„ë‹¨í•œ ê°€ì´ë“œ ìš”ì²­.
    ì‘ë‹µì€ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ 5ë‹¨ê³„ë¡œ ìš”ì•½ë˜ë©°, 200ì ë‚´ì™¸ë¡œ ì œí•œë¨.
    """

    prompt = f"""
ë‹¹ì‹ ì€ í”¼ë¶€ ê±´ê°• ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ í”¼ë¶€ ì§ˆí™˜ì— ëŒ€í•´ 200ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ ì•ˆë‚´í•´ì£¼ì„¸ìš”.

í”¼ë¶€ ì§ˆí™˜ëª…: {disease_name}

ì•„ë˜ í˜•ì‹ì— ë”°ë¼ í•œêµ­ì–´ë¡œ ì •í™•í•˜ê³  ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”:

1. ì§ˆí™˜ ì„¤ëª…: ì¼ë°˜ì¸ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê°„ë‹¨íˆ
2. ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­: ì‘ê¸‰ì„± ì—¬ë¶€ í¬í•¨
3. ê°€ì • ê´€ë¦¬ ë°©ë²•: ì†ì‰½ê²Œ ì‹¤ì²œ ê°€ëŠ¥í•œ íŒ
4. ì „ë¬¸ ì¹˜ë£Œ ë°©ë²•: ë³‘ì›ì—ì„œ ë°›ì„ ìˆ˜ ìˆëŠ” ì¹˜ë£Œ
5. ì£¼ì˜ì‚¬í•­: ì¬ë°œ, ê°ì—¼, ìê°€ ì¹˜ë£Œ ê²½ê³  ë“±

ê° í•­ëª©ì€ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì œì‹œí•˜ì„¸ìš”.
ë‹µë³€ì€ 200ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """.strip()

    print(f"\n[{OLLAMA_MODEL} ëª¨ë¸ì—ê²Œ ì¡°ì–¸ì„ ìš”ì²­í•©ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.]")

    try:
        response = ollama.chat(
            model=OLLAMA_MODEL,
            messages=[{'role': 'user', 'content': prompt}]
        )
        return response['message']['content'].strip()

    except Exception as e:
        return f"[ì˜¤ë¥˜] Ollama ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\nOllama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”."

# --- TTS ---
from gtts import gTTS
import os

def speak_korean_gtts(text):
    try:
        tts = gTTS(text=text, lang='ko', slow=False)
        original = "tts_output_original.mp3"
        faster = "tts_output_fast.mp3"

        tts.save(original)

        # ğŸ› ï¸ ffmpegë¡œ ì†ë„ 1.5ë°° ë¹ ë¥´ê²Œ ë³€í™˜ (tempo=1.5)
        os.system(f"ffmpeg -y -i {original} -filter:a 'atempo=1.5' {faster}")

        # ğŸš ì¬ìƒ
        os.system(f"mpg123 {faster}")

        # ğŸ§¹ ì •ë¦¬
        os.remove(original)
        os.remove(faster)
        print(f"[ğŸ§¹] mp3 íŒŒì¼ ìë™ ì‚­ì œ ì™„ë£Œ..")

    except Exception as e:
        print(f"[TTS ì˜¤ë¥˜] {e}")

# --- ë©”ì¸ ë¡œì§ ---
def main():
    print("ìµœì í™”ëœ ONNX ê¸°ë°˜ í”¼ë¶€ ì§ˆí™˜ ì§„ë‹¨ ì‹œìŠ¤í…œ")
    print("=" * 55)
    
    # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
    print(f"ğŸ’» CPU ì½”ì–´: {psutil.cpu_count(logical=False)} ë¬¼ë¦¬ / {psutil.cpu_count(logical=True)} ë…¼ë¦¬")
    print(f"ğŸ§  ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬: {psutil.virtual_memory().available / (1024**3):.1f} GB")
    print(f"âš¡ ì‚¬ìš© ê°€ëŠ¥í•œ ONNX Providers: {ort.get_available_providers()}")
    print("=" * 55)
    
    if not os.path.exists(CAPTURE_FOLDER):
        os.makedirs(CAPTURE_FOLDER)
    
    model, model_type = initialize_optimized_model()
    if model is None:
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“Š ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸: {model_type}")
    
    if model_type and ("ONNX" in model_type or "ìµœì í™”" in model_type):
        test_data = np.random.random((1, 96, 96, 3)).astype(np.float32)
        avg_time, fps = benchmark_model(model, test_data)
        async_predictor = AsyncPredictor(model)
        use_async = True
        print("ğŸ”„ ë¹„ë™ê¸° ì˜ˆì¸¡ ëª¨ë“œ í™œì„±í™”")
    else:
        use_async = False
        print("â³ ë™ê¸° ì˜ˆì¸¡ ëª¨ë“œ ì‚¬ìš©")
    
    font_path = get_system_font_path()
    try:
        if font_path and os.path.exists(font_path):
            font = ImageFont.truetype(font_path, 20)
            small_font = ImageFont.truetype(font_path, 14)
            print(f"âœ… í°íŠ¸ ë¡œë“œ ì„±ê³µ: {font_path}")
        else:
            font = ImageFont.load_default()
            small_font = ImageFont.load_default()
            print("âš ï¸ ì‹œìŠ¤í…œ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤")
    except IOError:
        font = ImageFont.load_default()
        small_font = ImageFont.load_default()
        print("âš ï¸ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤")

    cap = open_camera()
    if cap is None:
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    try_set(cap, cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*"MJPG"))
    try_set(cap, cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
    try_set(cap, cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
    try_set(cap, cv2.CAP_PROP_FPS, CAMERA_FPS)

    window_name = "ONNX Skin Disease Diagnosis"
    cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)

    frame_count = 0
    fps_start_time = time.time()
    current_fps = 0.0

    measuring_mode = False
    measuring_class = None
    measuring_start_time = None
    MEASURING_DURATION = 5  # ì´ˆ

    while True:
        ret, frame = cap.read()
        if not ret:
            print("ì˜¤ë¥˜: ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            break

        h, w, _ = frame.shape
        min_dim = min(h, w)
        start_x = (w - min_dim) // 2
        start_y = (h - min_dim) // 2
        crop_frame = frame[start_y:start_y+min_dim, start_x:start_x+min_dim]

        img_array = cv2.resize(crop_frame, (96, 96))
        img_array = np.expand_dims(img_array, axis=0).astype(np.float32) / 255.0

        if use_async:
            async_predictor.predict_async(img_array)
            predictions = async_predictor.get_prediction()
        else:
            predictions = model.predict(img_array, verbose=0) if not hasattr(model, 'session') else model.predict(img_array)

        if predictions is not None:
            predicted_idx = np.argmax(predictions[0])
            confidence = predictions[0][predicted_idx]
        else:
            predicted_idx = 0
            confidence = 0.0

        current_class = predicted_idx

        # ì¸¡ì • ëª¨ë“œ ì§„ì… ì‹œ ìœ ì§€ íŒë‹¨
        if measuring_mode:
            if measuring_class == current_class:
                elapsed_time = time.time() - measuring_start_time
                if elapsed_time >= MEASURING_DURATION:
                    final_class_name = class_names_kr[measuring_class]
                    print("\n" + "="*50)
                    print(f"âœ… ìµœì¢… ì§„ë‹¨: {final_class_name} (5ì´ˆ ì´ìƒ ì§€ì†)")
                    print("="*50)
                    solution = get_solution_from_gemma(final_class_name)
                    print("\n[Ollama Gemma3ì˜ ê±´ê°• ì¡°ì–¸]")
                    print(solution)
                    print("\n(ì£¼ì˜: ì´ ì •ë³´ëŠ” ì°¸ê³ ìš©ì´ë©°, ì •í™•í•œ ì§„ë‹¨ê³¼ ì¹˜ë£Œë¥¼ ìœ„í•´ ë°˜ë“œì‹œ ì „ë¬¸ ì˜ë£Œê¸°ê´€ì„ ë°©ë¬¸í•˜ì„¸ìš”.)")
                    speak_korean_gtts(solution)
                    measuring_mode = False
            else:
                measuring_class = current_class
                measuring_start_time = time.time()

        frame_count += 1
        if frame_count % 30 == 0:
            fps_end_time = time.time()
            current_fps = 30 / (fps_end_time - fps_start_time)
            fps_start_time = fps_end_time

        img_pil = Image.fromarray(cv2.cvtColor(crop_frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(img_pil)

        draw.text((10, 10), f"ğŸ”¬ ì‹¤ì‹œê°„ ì˜ˆì¸¡ ({model_type}):", font=font, fill=(0, 255, 0))
        draw.text((10, 35), f"{class_names_kr[current_class]} ({confidence*100:.1f}%)", font=font, fill=(0, 255, 0))
        draw.text((10, 65), f"âš¡ FPS: {current_fps:.1f}", font=small_font, fill=(255, 255, 0))

        if hasattr(model, 'session'):
            provider_info = model.session.get_providers()[0]
            draw.text((10, 85), f"ğŸ’» Provider: {provider_info.replace('ExecutionProvider', '')}", font=small_font, fill=(255, 255, 0))

        display_frame = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        cv2.imshow(window_name, display_frame)

        key = cv2.waitKey(1) & 0xFF

        if key == ord('b') and ("ONNX" in model_type or "ìµœì í™”" in model_type):
            print("\n" + "="*50)
            print("ğŸƒ ì‹¤ì‹œê°„ ë²¤ì¹˜ë§ˆí‚¹ ì‹¤í–‰")
            print("="*50)
            avg_time, fps = benchmark_model(model, img_array)

        elif key == ord('c'):
            print("ğŸ•µï¸â€â™€ï¸ ì¸¡ì • ëª¨ë“œ í™œì„±í™” (5ì´ˆ ì´ìƒ ë™ì¼ í´ë˜ìŠ¤ ìœ ì§€ ì‹œ ì§„ë‹¨)")
            measuring_mode = True
            measuring_class = current_class
            measuring_start_time = time.time()

        elif key == ord('q'):
            print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

    cap.release()
    cv2.destroyAllWindows()


# --- ì¹´ë©”ë¼ í—¬í¼ í•¨ìˆ˜ -------------------------------------------------

def open_camera(indices=(0, 1, 2)):
    """ì—¬ëŸ¬ ì¸ë±ìŠ¤ë¥¼ ìˆœíšŒí•˜ë©° ì •ìƒ í”„ë ˆì„ì„ ë°˜í™˜í•˜ëŠ” ì¹´ë©”ë¼ ê°ì²´ë¥¼ ì°¾ëŠ”ë‹¤."""
    for idx in indices:
        cap = cv2.VideoCapture(idx)
        if not cap.isOpened():
            continue

        ok, frame = cap.read()
        if ok and frame is not None and frame.size > 0:
            print(f"âœ… ì¹´ë©”ë¼ {idx}ë²ˆ ì •ìƒ ë™ì‘ (ê¸°ë³¸ ì„¤ì •)")
            return cap

        # ì •ìƒ í”„ë ˆì„ì´ ì•„ë‹ˆë©´ í•´ì œ í›„ ë‹¤ìŒ ì¸ë±ìŠ¤ ì‹œë„
        cap.release()
    return None

def try_set(cap, prop, value):
    """ì¹´ë©”ë¼ ì†ì„± ì„¤ì • ì‹œë„ í›„ ì‹¤íŒ¨í•˜ë©´ ì›ë³µ."""
    old_val = cap.get(prop)
    cap.set(prop, value)
    ok, frame = cap.read()
    if not ok or frame is None or frame.size == 0:
        cap.set(prop, old_val)
        print(f"âš ï¸ ì†ì„± ì„¤ì • ì‹¤íŒ¨ â†’ ì›ë³µ: {prop}={value}")
        return False
    return True

if __name__ == "__main__":
    main() 
